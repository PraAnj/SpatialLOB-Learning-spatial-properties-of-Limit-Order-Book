{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# import tensorflow as tf\n",
    "from keras import layers, optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape, TimeDistributed, Input, LSTM\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "window_size = 100 # 64 or 32 length LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_functional():\n",
    "    input_lmd = Input(shape=(20, 64, 1)) # grayscale image = (20x64)\n",
    "    input_shape = Input(shape=(window_size, 20, 64, 1))\n",
    "    \n",
    "    # build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 3), padding='same')(input_lmd)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (3, 1))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = MaxPooling2D((1, 4), strides=(1, 4), padding='same')(conv_first1) # 18x16\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 3), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (3, 1))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = MaxPooling2D((1, 4), strides=(1, 4), padding='same')(conv_first1) # 16x4\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 5), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (5, 1))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = MaxPooling2D((1, 4), strides=(1, 4), padding='same')(conv_first1) # 12x1\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(32, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(32, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(32, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(32, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(32, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3) # axis=3 for filter axis\n",
    "\n",
    "    # Flattern output to feed 1D vector to LSTM\n",
    "    conv_flat = Flatten()(convsecond_output)\n",
    "    \n",
    "    # CNN model\n",
    "    model_cnn = Model(inputs=input_lmd, outputs=conv_flat)\n",
    "\n",
    "    # time distributed layer\n",
    "    processed_sequences = TimeDistributed(model_cnn)(input_shape)\n",
    "    \n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = LSTM(32)(processed_sequences)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model_cnn_lstm = Model(inputs=input_shape, outputs=out)\n",
    "    adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1)\n",
    "    model_cnn_lstm.compile(optimizer=adam, loss='categorical_crossentropy', metrics=[keras.metrics.Accuracy(),\n",
    "                                                                            keras.metrics.CategoricalAccuracy(),\n",
    "                                                                            keras.metrics.CategoricalCrossentropy(),\n",
    "                                                                            keras.metrics.Precision(),\n",
    "                                                                            keras.metrics.Recall()])\n",
    "    return model_cnn, model_cnn_lstm\n",
    "\n",
    "model_cnn, cnn_lob_model = model_functional()\n",
    "# model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_InceptionV3_extractor():\n",
    "    # create the base pre-trained model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    inception_model = Dense(1024, activation='relu')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model_cnn = Model(inputs=base_model.input, outputs=inception_model)\n",
    "\n",
    "    # time distributed layer\n",
    "    input_shape = Input(shape=(window_size, 20, 64, 1))\n",
    "    processed_sequences = TimeDistributed(model_cnn)(input_shape)\n",
    "    \n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = LSTM(64)(processed_sequences)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model_cnn_lstm = Model(inputs=input_shape, outputs=out)\n",
    "    model_cnn_lstm.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                           loss='categorical_crossentropy', metrics=[keras.metrics.Accuracy(),\n",
    "                                                                            keras.metrics.CategoricalAccuracy(),\n",
    "                                                                            keras.metrics.CategoricalCrossentropy(),\n",
    "                                                                            keras.metrics.Precision(),\n",
    "                                                                            keras.metrics.Recall()])\n",
    "    return model_cnn, model_cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_VGG19_extractor():\n",
    "    # create the base pre-trained model\n",
    "    base_model = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # let's add a fully-connected layer\n",
    "    vgg_model = Dense(1024, activation='relu')(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model_cnn = Model(inputs=base_model.input, outputs=vgg_model) # outputs=base_model.get_layer('block4_pool').output\n",
    "\n",
    "    # time distributed layer\n",
    "    input_shape = Input(shape=(window_size, 20, 64, 1))\n",
    "    processed_sequences = TimeDistributed(model_cnn)(input_shape)\n",
    "    \n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = LSTM(64)(processed_sequences)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model_cnn_lstm = Model(inputs=input_shape, outputs=out)\n",
    "    model_cnn_lstm.compile(optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "                           loss='categorical_crossentropy', metrics=[keras.metrics.Accuracy(),\n",
    "                                                                            keras.metrics.CategoricalAccuracy(),\n",
    "                                                                            keras.metrics.CategoricalCrossentropy(),\n",
    "                                                                            keras.metrics.Precision(),\n",
    "                                                                            keras.metrics.Recall()])\n",
    "    return model_cnn, model_cnn_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
